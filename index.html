<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8" />
    <title>title</title>
    <p>
        Module Three or week three focuses on hardware support for achieving isolation in trusted computing. The previous two weeks covered the concept of a trusted computing base, which protects resources requiring protection. The key to achieving this protection is by isolating the trusted computing base from untrusted code, which is facilitated by hardware support. The module aims to explore the functionality provided by modern processors that assist in achieving isolation.

        Isolation is not only important for separating the trusted computing base from untrusted application code but also for ensuring that different applications remain isolated from each other. This means that when debugging an application, any issues encountered are attributed to the code within that specific process, rather than assuming interference from other concurrently running processes. The logical isolation between processes helps in maintaining accountability and identifying the root cause of errors.
        
        To understand how hardware enables isolation, the module delves into the representation of processes within the trusted computing base, the execution and switching of processes, and the management of physical resources such as memory that store instructions and data. Exploring these details will provide a comprehensive understanding of how hardware contributes to achieving isolation.
        
        Overall, the module aims to provide insights into the role of hardware in enabling isolation, focusing on process representation, execution, resource management, and other relevant details.
    </p>

    <p>
        The discussion emphasizes the importance of isolation, both for the trusted computing base and user applications. Achieving isolation relies on assumptions of trust in the hardware and its functionality. While acknowledging concerns such as hardware vulnerabilities and supply chain issues, the current focus is on trusting the hardware, particularly in the context of Intel processors.

Hardware provides two crucial mechanisms for achieving isolation. First, it offers different execution modes or privilege levels, enabling the hardware to differentiate between executing untrusted user code and the trusted computing base. This awareness of the execution mode is essential. Second, the hardware incorporates privileged instructions. These instructions, defined by the processor's instruction set architecture, are restricted from execution in the user mode. Only in the system or privilege mode can these privileged instructions be successfully executed. This ensures that a subset of instructions remains exclusive to the trusted computing base and cannot be executed outside of it.

The module aims to explore these mechanisms within the X86 architecture. While specific details of the architecture are not the primary focus, the goal is to understand the concepts underlying hardware support for protection and isolation.

When discussing protection and isolation, it is important to consider what needs to be safeguarded. In this case, systems run programs or processes, which are the active entities making requests for resources. Processes operate within address spaces that encapsulate memory. A processor executing a process fetches instructions from memory based on logical addresses. These logical addresses may require translation to physical addresses to access the actual physical memory. Thus, there is a need for a mapping structure to ensure that logical addresses correspond to the correct physical addresses.

The idea behind memory protection and isolation is straightforward. Each process is only permitted to access the memory allocated or assigned to it. Access to the trusted computing base or other process memory is restricted. The module introduces the concept of base and bounds registers, which define the start and size of a process's memory allocation. These registers prevent a process from exceeding its allocated bounds. Loading and managing these registers is a responsibility of the trusted computing base or privileged instructions, as only they can execute these operations.

In summary, the module explores the hardware's role in achieving isolation and protection, focusing on execution modes, privileged instructions, logical and physical addresses, memory mapping, and the base and bounds registers. The goal is to understand the underlying concepts that support hardware-based protection mechanisms.
    </p>

    <p>
        In this lesson, we discussed the concept of an address space and how it is supported by modern processors, focusing on the Intel x86 architecture. The address space is a container for the code and data that a process can access and execute. We looked at the logical address space, which is divided into segments, and each segment can further be divided into pages.

To facilitate the mapping from logical to physical addresses, we use segment tables and page tables. In the x86 architecture, the global descriptor table contains segment descriptors that hold information about each segment. The trusted computing base (TCB) has its own segment descriptors, while each program has its local segment descriptors.

The logical address space can be divided into two main parts: the trusted computing base (kernel space) and the user code and data (user space). The kernel space is shared among all processes, while the user space is unique to each process. Within the user space, there are segments for code, heap, and stack.

We discussed the overall structure of the address space and its division into segments but didn't delve into the details of protection mechanisms. In the next lesson, we will explore how logical addresses are mapped to physical addresses.
    </p>
    
    <p>
        In the previous lesson, we discussed the concept of address spaces, including logical address spaces and physical memory. To access instructions or data, we need to translate logical addresses to physical addresses. This translation is achieved using a data structure called a segment table, which stores information about the location of each segment in physical memory.

        In the logical address space, addresses are divided into segments, and each segment is assigned a segment number. To translate a logical address to a physical address, we use the segment number and a displacement value. The segment table maps each segment to its starting address in physical memory. By retrieving the segment's starting address from the segment table and adding the displacement, we can compute the physical address.
        
        The segment table is a crucial data structure for address translation. It allows us to determine the physical location of a segment based on its segment number. The segment table entries contain information about the starting address of each segment in physical memory.
        
        The process of computing the physical address involves accessing the segment table based on the segment number provided in the logical address. The segment table entry corresponding to the segment number is retrieved, indicating the starting address of the segment in physical memory. The displacement is then added to this starting address to obtain the final physical address.
        
        However, this explanation is simplified, and in actual x86 architecture, additional complexities arise. For example, there are separate descriptor tables for the user and system portions of the address space, known as the Local Descriptor Table (LDT) and the Global Descriptor Table (GDT), respectively. Also, the x86 architecture includes segment selectors and page tables that further complicate the translation process.
        
        The main takeaway from this lesson is the concept of address translation using segment tables. In the next lesson, we will delve into a more detailed example to understand how this process works in practice.
    </p>

    <p>
        In the previous lesson, we discussed the process of translating logical addresses into physical addresses using a segment table. We compared this process to using a phone book to find a phone number based on a name. In this lesson, we will focus on address translation in the x86 architecture, specifically in Intel processors.

The address translation process involves several types of addresses. The logical address, also known as a far pointer, is the address specified by the program. It consists of a segment number and an offset within that segment. The segment number is stored in a segment selector, which is typically a register.

To translate the logical address, we use a segment table called the descriptor table, specifically the global descriptor table (GDT). The segment index is used to index into the GDT, which contains segment descriptors. By performing some arithmetic with the index, we can retrieve the segment descriptor from the GDT.

The segment descriptor helps us construct an address in the linear address space. The linear address space is the complete address space defined by the processor. It encompasses the operating system, user code, user data, stack, heap, and other components. Adding the offset to the linear address space results in the specific linear address corresponding to the logical address.

Next, the linear address is split into different fields. In a 32-bit architecture, the rightmost 12 bits represent the offset within a page. The next two sets of 9 bits (after subtracting 12 from 32) represent a table index and an index into the directory. Instead of using a single table, the x86 architecture employs a two-level table structure. The first level is a directory called the page table directory, which helps locate the page table for the given linear address.

By using the table indexes, we can locate the page table entry in the page table. The page table entry contains the physical address where the page starts in physical memory. This information is crucial for constructing the final physical address. If virtual memory is employed, there may be a page fault if the page is not currently in physical memory.

Once the physical address of the page is determined, it is page-aligned. The offset is added to this address to construct the final physical address needed for memory operations.

In the case of 64-bit architecture, the address translation process is slightly different. The descriptor table, which played a role in 32-bit addressing, is no longer significant. All segments are assumed to start at base 0, and the linear address is built using offsets within the segments. In this mode, only 48 bits of the 64-bit address are used, which still provides a large address space.

Address translation in 64-bit architecture involves a four-level page table structure. The top-level table is called the page map level 4, followed by the page directory pointer table, the page directory, and the page table. Each level is indexed using a set of 9 bits, which corresponds to 512 entries. The page table entries are 8 bytes long.

The translation process begins with a register pointing to the start of the top-level table. The 9 bits from the linear address index into the page map level 4, which directs us to the page directory pointer table. This pattern continues as each level's entry points to the next level's table until we reach the page table. The page table entry contains the physical address of the page.

Address translation can be a complex process, especially in 64-bit architecture due to the wider address space. It involves traversing the levels of page tables using the 9-bit indices and retrieving the physical address of the page. The details of this process can be found in the Intel software developer manual, particularly in Chapter 4.

Understanding address translation is essential for comprehending memory protection, which will be discussed
    </p>
        
    <p>
        In summary, the address translation process involves splitting the address space into logical segments or pages. The tables used for address translation, such as page tables and segment tables, are accessed during program execution. These tables dictate the physical memory locations that can be accessed by a process. To ensure protection and isolation, these tables are allocated in the operating system portion of the address space, which is part of the trusted computing base. If these tables were accessible to the user, they could modify them and bypass the intended memory protection. Certain registers, like CR3, point to these tables and control their locations. Loading these registers can only be done by the trusted computing base through special privilege instructions. By managing these mappings, the operating system can protect and isolate the operating system itself from untrusted user code, as well as protect programs from accessing each other's memory without explicit sharing. Although the address translation process may introduce some slowdown due to memory accesses, hardware can mitigate this with the help of a Translation Lookaside Buffer (TLB). The TLB stores recent virtual-to-physical address mappings, reducing the need to access the translation tables for every memory access. This overview of address translation provides a simplified understanding, and further details can be explored in an operating systems class or relevant readings. The next lesson will delve into memory protection and explain how isolation is guaranteed.
    </p>

    <p>
        In this section, we delved into the topic of memory protection, which is essential for achieving isolation and ensuring the security of program memory. We focused on memory protection in the x86 architecture, specifically discussing segments and their role in protecting data and code. Each segment has a segment descriptor, which not only contains information for address translation but also includes a protection level. Segments can have four different protection levels, with level 0 being the most privileged.

We explored three important concepts related to memory protection: the current protection level (CPL), the request or privilege level (RPL), and the descriptor protection level (DPL). The CPL represents the privilege level at which the processor is currently executing, while the RPL is a privilege level specified when requesting access to a segment. The hardware performs a protection check by comparing the maximum of CPL and RPL with the DPL of the target segment. For access to be allowed, the maximum privilege level must be less than or equal to the DPL.

The RPL serves as a means to prevent privilege escalation. Even when executing more privileged code, a lower privilege level can be requested by setting a higher value in the RPL portion of the segment selector. This ensures that the code can only access data at the specified lower privilege level.

We also examined an example that demonstrated how memory protection works when accessing data segments from different privilege levels. The hardware-enforced protection check prevents code running at a higher privilege level from accessing data in segments with lower privilege levels. However, code running at a lower privilege level can access data in segments with equal or lower privilege levels.

This segment-level memory protection is enforced by the hardware itself. By defining different segments within an address space and assigning them different privilege levels, the hardware ensures that lower privilege levels cannot access higher privilege level data, such as kernel data. Additionally, even privileged code can be restricted to accessing only low privilege level data by utilizing the RPL mechanism.

This overview provides a foundational understanding of memory protection at the segment level. In the next lesson, we will explore further aspects related to memory protection.
    </p>

    <p>
        In this lesson, we delved deeper into memory protection concepts, focusing on the details of segment-level memory protection. We discussed conforming and non-conforming code segments. Conforming code segments allow execution to continue at the same privilege level even when transferring to a higher privileged segment, while non-conforming code segments require privilege level changes, usually done through special entry points like call gates or system call instructions.

We also explored page protection bits, which come into play when segments are paged. Each page within a segment can have a page protection level (PPL) of either privilege level (0) or non-privilege level (1). When accessing a page, the PPL must match the current privilege level (CPL). Additionally, pages can have read-write protection and execute-disable protection bits, determining if they can be read from, written to, or executed.

By combining segment and page protection bits, ranges of addresses within a segment or across address spaces can be protected, providing granular control over memory access and ensuring isolation and security. These hardware memory protection mechanisms enforce privilege restrictions and safeguard data and code within an address space.
    </p>

    <p>
        In this lesson, we focused on the mechanism of privilege level changes, specifically when transitioning from user code to system code. The primary method for such transitions is through system calls, which allow user-level code to access higher privileged resources or perform privileged operations. We discussed various ways in which privilege level changes can occur.

The traditional approach involves using a special entry point called a Call Gate. Call Gates specify the code segment to be accessed, the required privilege level for the caller, the entry point of the procedure to be called, and any necessary parameter and stack switches. By using Call Gates, privilege level changes can be controlled and enforced.

However, modern processors offer dedicated instructions to handle privilege level changes more efficiently. For example, Intel processors provide instructions such as SYSENTER and SYSEXIT. SYSENTER is used to transfer control and change the privilege level from user (CPL 3) to system (CPL 0), while SYSEXIT allows the reverse transition from system to user level. These instructions utilize specific machine registers to store necessary information like target code segment, stack segment, stack pointer, and the location for resuming execution in user space.

It's important to note that the processor enforces memory access restrictions based on the current privilege level. User-level code (CPL 3) is only allowed to access user code and user data. To access the operating system or privileged resources, a system call must be made using the supported hardware mechanisms such as system call instructions, call gates, or the interrupt table.

Understanding privilege levels and the methods for transitioning between them enables controlled access to privileged operations while maintaining system security and isolation.
    </p>

    <p>
        In the recent lessons, we have covered topics such as address translation, memory protection, privilege levels, and changing between privilege levels. Now, we will explore how these changes occur, specifically when transitioning from user code to the system or operating system level. This transition is typically achieved through system calls, which allow user code to access protected resources or change privilege levels.

The traditional approach for privilege level changes involved using special entry points called "Call Gates." Call Gates specify the code segment to be accessed, the required privilege level for the caller, the entry point for the procedure to be called, and other parameters. However, modern processors provide instructions like SYSENTER and SYSEXIT (or SYSCALL and SYSRET) to perform system calls more efficiently.

Privileged instructions are special instructions that can only be executed when running at the highest privilege level (CPL 0), which is in the operating system. Attempting to execute these instructions at user level will result in failure or faults. Privileged instructions include operations such as loading the Global Descriptor Table (GDT) register, manipulating the Local Descriptor Table (LDT), controlling registers (e.g., CR3), halting the processor, and accessing performance monitoring or machine-specific registers. These instructions affect memory mapping, translation, and protection, and are restricted to the trusted computing base or operating system.

By utilizing privilege levels and privileged instructions, the hardware enforces isolation and protects the trusted computing base from untrusted code. User code is restricted to accessing only user-level resources, and system access is granted through controlled entry points like system calls. This ensures the isolation of the trusted computing base from untrusted code and provides protection between different programs as well.

The hardware mechanisms discussed in these lessons fulfill the requirement of isolating the trusted computing base from untrusted code. The processor operates in different modes, such as CPL 0, and the privileged instructions can only be executed in the operating system mode. These features, combined with memory protection and address translation, contribute to achieving a trusted computing base.

In the next lessons, a few more topics will be covered before wrapping up the discussion.
    </p>

    <p>
        In the previous lesson, we discussed how hardware mechanisms such as memory protection and privileged instructions help meet the isolation requirement for a trusted computing base (TCB). However, it is important to acknowledge that we cannot blindly trust hardware to provide complete protection. There are vulnerabilities and attacks that can compromise the TCB. One example is the Row Hammer Attack, which exploits a specific DRAM behavior to cause bit flips in adjacent memory cells. By manipulating memory in this way, an attacker can gain unauthorized access to operating system data and defeat memory protection.

In addition to hardware attacks, there are software attacks that target the TCB, such as kernel rootkits. These malicious software can run in kernel mode and have the ability to modify OS memory, compromising the isolation guarantee. Vulnerabilities in the kernel code can be exploited to execute arbitrary code with kernel privileges, further undermining the TCB's integrity.

It is important to be aware of these vulnerabilities and attacks, as they can negate the isolation guarantee provided by the hardware mechanisms we discussed. While the hardware plays a crucial role in enforcing security, it is not infallible. Software vulnerabilities and attacks can still pose a significant risk to the TCB.
    </p>

    <p>
        In this lesson, we explored how system-level protections can contribute to software security. One of these protections is Address Space Layout Randomization (ASLR), which randomizes the starting addresses of different segments within the address space. By making it difficult for attackers to determine the exact location of code or variables, ASLR mitigates certain software vulnerabilities, such as buffer overflows.

Another hardware-based protection is the use of NX (Never Execute) or DX (Disable Execute) bits in processors. These bits prevent code execution from certain regions, such as the stack. By disabling the execution of code placed on the stack, NX/DX bits help defend against buffer overflow attacks that rely on executing malicious code from the stack.

While ASLR and NX/DX bits raise the bar for attackers and provide system-level solutions to software security, it is important to note that they do not completely eliminate vulnerabilities like buffer overflows. Advanced techniques like return-oriented programming and return-to-libc attacks can still bypass these protections.

Overall, these solutions enhance software security by making it harder for attackers to exploit vulnerabilities. They leverage concepts of address space layout and memory protection discussed in this module. In the next lesson, we will summarize the key points covered in this module before concluding.
    </p>

    <p>

        In this module, we focused on the role of hardware in achieving isolation and memory protection for the trusted computing base. Here's a summary of the key points covered:

1. Address Space and Memory Translation: We discussed the concept of an address space and the translation process from logical/virtual addresses to physical addresses. This translation is necessary to isolate the trusted computing base and ensure programs work with logical addresses.

2. Memory Protection: Memory protection is crucial for separating operating system code and user code. We explored the mechanisms that enable this separation, such as protection level bits (DPL, CPL, RPL) and page protection levels. These mechanisms ensure that user code cannot access or modify the memory belonging to the operating system without going through defined entry points.

3. Privileged Instructions: We learned about privileged instructions, which can only be executed by the trusted computing base or operating system. These instructions and the different execution modes (CPL) of the processor are essential for achieving isolation.

4. Trust in Hardware: While hardware provides the foundation for memory protection and isolation, it is not immune to vulnerabilities. Attacks targeting hardware and firmware are regularly reported, which emphasizes the importance of trusting the hardware fully.

5. Further Reading: The Intel developers' documentation provides more detailed information on address translation, memory protection, and related concepts. Additional reading on specific attacks like the row hammer attack was also recommended.

Looking ahead, the next module will focus on the requirement of complete mediation and delve into the topic of virtualization.
    </p>

    <p>
        Certainly! In this module, we explored the role of hardware in achieving isolation and memory protection for the trusted computing base. We started by understanding the process of address translation from logical to physical addresses, which allows programs to work with logical addresses without being concerned about the underlying physical memory. Memory protection mechanisms, including protection level bits and page protection levels, were discussed to ensure the separation of operating system code and user code. Privileged instructions and different execution modes of the processor were introduced as crucial components of isolation. However, it was emphasized that trust in hardware is essential, as vulnerabilities in hardware and firmware can undermine the effectiveness of memory protection. The module concluded by highlighting the Intel developers' documentation as a recommended resource for further reading. In the next module, we will explore the concept of complete mediation and delve into virtualization.
    </p>

    <p>
        Of course! In this module, we talked about how hardware helps protect the important parts of a computer system from unauthorized access. We started by understanding how the computer translates the logical addresses that programs use into physical addresses that correspond to the actual memory locations. This translation process allows programs to work with a virtual address space without worrying about the physical memory details.

We also discussed memory protection, which is a way to separate the operating system from user programs. This separation ensures that user programs cannot access or modify the sensitive parts of the system, such as the operating system code or data, directly. Memory protection relies on a combination of protection level bits and page protection levels, which control the access rights to different parts of memory.

We learned that there are certain instructions that only the trusted parts of the system, like the operating system, can use. These instructions are called privileged instructions, and they help enforce the separation between trusted and untrusted code. By executing in different modes, the processor can differentiate between when it's running the operating system code and when it's running user code.

However, it's important to remember that hardware vulnerabilities can exist, which may undermine the effectiveness of memory protection. These vulnerabilities can be found in the hardware or firmware of the system, and they can be exploited by attackers. So, while hardware plays a crucial role in providing security, we need to be aware of potential vulnerabilities and keep our systems up to date with security patches.

In the next module, we will explore another important concept called complete mediation, and we'll discuss how virtualization can help achieve it.
    </p>
</head>
<body>
    
</body>
</html>